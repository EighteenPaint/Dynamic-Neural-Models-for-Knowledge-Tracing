{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LERqDO59VeaM",
    "outputId": "1d48b66a-4bbb-4967-f2e5-6de7f6b78137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version = 2.4.0-dev20200731\n",
      "/home/kostas/Code/Marina/tdnn_skill_names_w2v\n",
      "current dir : /home/kostas/Code/Marina/tdnn_skill_names_w2v\n",
      "rootdir : /home/kostas/Datasets/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, Activation, Dense, \\\n",
    "                                    Flatten, Dropout, Conv1D, Reshape, BatchNormalization,\\\n",
    "                                        GRU, Bidirectional,SpatialDropout1D, GaussianDropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.initializers import Constant, RandomUniform\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print('Tensorflow version = {}'.format(tf.__version__))\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import sys\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "rootdir = \"/home/kostas/Datasets/\"\n",
    "print(\"current dir : {}\".format(os.getcwd()))\n",
    "print(\"rootdir : {}\".format(rootdir) )\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {
    "id": "YIW1W1AoV84d"
   },
   "outputs": [],
   "source": [
    "USE_W2V = True\n",
    "#USE_W2V = False \n",
    "#emb_size = 300\n",
    "emb_size = 300\n",
    "#w2v_emb_size = 300 \n",
    "w2v_emb_size = 100\n",
    "L = 50\n",
    "max_epochs = 30\n",
    "beta = 1e-3\n",
    "#mod =  'tdnn_model' \n",
    "mod =  'bigru_model'\n",
    "spatd = None\n",
    "gausd = None\n",
    "if mod == 'bigru_model':\n",
    "    num_hidden = [50,25]\n",
    "    batch_size = 32\n",
    "    \n",
    "elif mod == 'tdnn_model':\n",
    "    num_hidden = [20,15,10,5]\n",
    "    batch_size = 50\n",
    "    \n",
    "use_sigmoid = False\n",
    "CREATE_NEW_DATA_SPLIT = True\n",
    "global fold\n",
    "    \n",
    "#DATASET = 'Assistment2009_corrected'\n",
    "DATASET = 'assist2009_updated'\n",
    "#DATASET = 'fsaif1tof3'\n",
    "#DATASET = 'Assistment2012_13'\n",
    "#DATASET = 'Assistment2017'\n",
    "\n",
    "max_v_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPofwTBCXLYL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {
    "id": "hfL7IhFIWDPL"
   },
   "outputs": [],
   "source": [
    "# Function `printProgressBar`: function that prints progress bar in the console\n",
    "\n",
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '',\n",
    "                      decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd, flush=True)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {
    "id": "79P2REsXWHx3"
   },
   "outputs": [],
   "source": [
    "#Read file in 3-lines format and return `data` numpy array\n",
    "\n",
    "def read_file_3lines(file, start_user):\n",
    "    user_ids = []\n",
    "    skill_ids = []\n",
    "    correct = []\n",
    "    with open(file, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        cnt = 0\n",
    "        user_id = start_user\n",
    "        try:\n",
    "            num_responses = int(line)\n",
    "        except:\n",
    "            print('Error')\n",
    "        user_ids += [user_id]*num_responses\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line==\"\":\n",
    "                break\n",
    "            cnt += 1\n",
    "            if cnt%3 == 0:\n",
    "                user_id += 1\n",
    "                num_responses = int(line)\n",
    "                user_ids += [user_id]*num_responses\n",
    "            elif cnt%3 == 1:\n",
    "                skill_ids += line.replace(\"\\n\",\"\").split(\",\")\n",
    "            elif cnt%3==2:\n",
    "                correct += line.replace(\"\\n\",\"\").split(\",\")\n",
    "        user_ids = np.reshape(np.array(user_ids),[-1,1])\n",
    "        num_unique_users = np.unique(user_ids[:,0]).shape[0]\n",
    "        skill_ids = np.reshape(np.array(skill_ids).astype(int),[-1,1])\n",
    "        correct = np.reshape(np.array(correct).astype(int),[-1,1])\n",
    "        idx = np.reshape((correct==0) + (correct==1), [-1])\n",
    "        data = np.hstack((user_ids[idx], skill_ids[idx], correct[idx]))\n",
    "        return data, num_unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {
    "id": "1I9k1UNpWO-4"
   },
   "outputs": [],
   "source": [
    "def gen_inputs_targets(data, user_ids, N, prefix):\n",
    "    printProgressBar(0, N, prefix = prefix, suffix = 'Complete', length = 50)\n",
    "    \n",
    "    x = None\n",
    "    t = None\n",
    "    start = True\n",
    "    for i,student_id in enumerate(user_ids):\n",
    "        # Make an array with all the data for this student\n",
    "        student_data = data[data[:,0]==student_id]\n",
    "        skill_hist = toeplitz(student_data[:,1],0.0*np.ones([1,L]))\n",
    "        responses_hist = toeplitz(student_data[:,2],0.0*np.ones([1,L]))\n",
    "        student_data = np.hstack((skill_hist,\n",
    "                                np.fliplr(responses_hist)\n",
    "                                ))\n",
    "        if start:\n",
    "            start = False\n",
    "            x = student_data[1:,0:2*L-1]\n",
    "            t = student_data[1:,2*L-1].reshape([-1,1])\n",
    "        else:\n",
    "            x = np.vstack((x, student_data[1:,0:2*L-1]))\n",
    "            t = np.vstack((t, student_data[1:,2*L-1].reshape([-1,1])))\n",
    "        printProgressBar(i+1, N, prefix = prefix, suffix = 'Complete', length = 50)        \n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {
    "id": "RQiNtgbcWTSf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef read_data(DATASET = \\'assist2009_updated\\', I=None):\\n    if (DATASET == \\'assist2009_corrected\\') :\\n        train_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_train{}.csv\".format(I))\\n        valid_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_valid{}.csv\".format(I))\\n        test_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_test.csv\")\\n        # Read embedding data\\n        emb_file = path.join(rootdir, DATASET,\\'skill_name_embeddings_corrected.csv\\') #300dim\\n        #emb_file = path.join(rootdir, DATASET,\\'Assistment_2009_corrected_skname_embeddings_FastText.csv\\')\\n        #emb_file = path.join(rootdir, DATASET, \\'skill_name_embeddings_corrected_100d.csv\\')\\n        # Read skill names\\n        sknames_file = path.join(rootdir, DATASET,\\'skill_names_corrected.csv\\')\\n                \\n    elif DATASET == \\'assist2009_updated\\':\\n        train_file = path.join(rootdir,DATASET,\"assist2009_updated_train{}.csv\".format(I))\\n        valid_file = path.join(rootdir,DATASET,\"assist2009_updated_valid{}.csv\".format(I))\\n        test_file = path.join(rootdir,DATASET,\"assist2009_updated_test.csv\")\\n        # Read embedding data\\n        #emb_file = path.join(rootdir, DATASET, \\'skill_name_embeddings_updated300d.csv\\')\\n        #emb_file = path.join(rootdir, DATASET, \\'Assist2009_updated_skname_embeddings_FastText.csv\\')\\n        emb_file = path.join(rootdir, DATASET, \\'skill_name_embeddings_updated100d.csv\\')\\n        # Read skill names\\n        sknames_file = path.join(rootdir, DATASET,\\'skill_names_updated.csv\\')\\n        \\n    elif DATASET == \\'fsaif1tof3\\': \\n        train_file = path.join(rootdir,DATASET,\"fsaif1tof3_train{}.csv\".format(I))\\n        valid_file = path.join(rootdir,DATASET,\"fsaif1tof3_valid{}.csv\".format(I))\\n        test_file = path.join(rootdir,DATASET,\"fsaif1tof3_test.csv\")\\n        # Read embedding data\\n        emb_file = path.join(rootdir, DATASET,\\'fsaif1tof3_embeddings_300d.csv\\')\\n        #emb_file = path.join(rootdir, DATASET,\\'fsaif1tof3_embeddings_100d.csv\\')\\n        # Read skill names\\n        sknames_file = path.join(rootdir, DATASET,\\'skill_name_question_id.csv\\')\\n        \\n    elif DATASET == \\'Assistment2012_13\\':\\n        train_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_train{}_3lines.csv\".format(I))\\n        valid_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_valid{}_3lines.csv\".format(I))\\n        test_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_test.csv\")\\n        # Read embedding data\\n        emb_file = path.join(rootdir, DATASET, \\'skill_name_embeddings_12_13.csv\\') #w2v 300d\\n        #emb_file = path.join(rootdir, DATASET, \\'Assistment2012_13_skname_embeddings_FastText.csv\\')\\n        #emb_file = path.join(rootdir, DATASET, \\'skill_name_embeddings_updated100d.csv\\')\\n        # Read skill names\\n        sknames_file = path.join(rootdir, DATASET,\\'skill_names_12_13.csv\\')    \\n    elif DATASET == \\'Assistment2017\\':\\n        train_file = path.join(rootdir,DATASET,\"assistment2017_train{}.csv\".format(I))\\n        valid_file = path.join(rootdir,DATASET,\"assistment2017_valid{}.csv\".format(I))\\n        test_file = path.join(rootdir,DATASET,\"assistment2017_test.csv\")\\n        # Read embedding data\\n        #emb_file = path.join(rootdir, DATASET, \\'Assistment2017_skill_names_embeddings_300d.csv\\')\\n        emb_file = path.join(rootdir, DATASET, \\'assistment20017_skname_embeddings_FastText.csv\\')\\n        #emb_file = path.join(rootdir, DATASET, \\'Assistment2017_skill_names_embeddings_100d.csv\\')\\n        # Read skill names\\n        sknames_file = path.join(rootdir, DATASET,\\'skill_names_assistment2017.csv\\')    \\n        \\n    else :\\n        print (\\'Dataset file not found\\')\\n    \\n    skill_names = pd.read_csv(sknames_file, sep=\\',\\', header=None).values\\n    num_skills = skill_names.shape[0]     \\n    \\n    if USE_W2V:\\n        embeddings = pd.read_csv(emb_file, sep=\\',\\', header=None)# \\n        # Add a zero row at the beginning\\n        embeddings = np.vstack((np.zeros([1,w2v_emb_size]), embeddings))   \\n    else:\\n        #embeddings = None\\n        embeddings = np.zeros([num_skills,emb_size])\\n        embeddings = np.vstack((np.zeros([1,emb_size]), embeddings))\\n                   \\n    start_user = 1\\n    data_train, N_train = read_file_3lines(train_file, start_user)\\n    start_user += N_train\\n    data_valid, N_valid = read_file_3lines(valid_file, start_user)\\n    start_user += N_valid\\n    data_test, N_test = read_file_3lines(test_file, start_user)\\n    return data_train, data_test, data_valid, embeddings, skill_names\\n'"
      ]
     },
     "execution_count": 1301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def read_data(DATASET = 'assist2009_updated', I=None):\n",
    "    if (DATASET == 'assist2009_corrected') :\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_train{}.csv\".format(I))\n",
    "        valid_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_valid{}.csv\".format(I))\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_test.csv\")\n",
    "        # Read embedding data\n",
    "        emb_file = path.join(rootdir, DATASET,'skill_name_embeddings_corrected.csv') #300dim\n",
    "        #emb_file = path.join(rootdir, DATASET,'Assistment_2009_corrected_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_corrected_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_corrected.csv')\n",
    "                \n",
    "    elif DATASET == 'assist2009_updated':\n",
    "        train_file = path.join(rootdir,DATASET,\"assist2009_updated_train{}.csv\".format(I))\n",
    "        valid_file = path.join(rootdir,DATASET,\"assist2009_updated_valid{}.csv\".format(I))\n",
    "        test_file = path.join(rootdir,DATASET,\"assist2009_updated_test.csv\")\n",
    "        # Read embedding data\n",
    "        #emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_updated300d.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assist2009_updated_skname_embeddings_FastText.csv')\n",
    "        emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_updated100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_updated.csv')\n",
    "        \n",
    "    elif DATASET == 'fsaif1tof3': \n",
    "        train_file = path.join(rootdir,DATASET,\"fsaif1tof3_train{}.csv\".format(I))\n",
    "        valid_file = path.join(rootdir,DATASET,\"fsaif1tof3_valid{}.csv\".format(I))\n",
    "        test_file = path.join(rootdir,DATASET,\"fsaif1tof3_test.csv\")\n",
    "        # Read embedding data\n",
    "        emb_file = path.join(rootdir, DATASET,'fsaif1tof3_embeddings_300d.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET,'fsaif1tof3_embeddings_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_name_question_id.csv')\n",
    "        \n",
    "    elif DATASET == 'Assistment2012_13':\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_train{}_3lines.csv\".format(I))\n",
    "        valid_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_valid{}_3lines.csv\".format(I))\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment2012_13_3lines_test.csv\")\n",
    "        # Read embedding data\n",
    "        emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_12_13.csv') #w2v 300d\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assistment2012_13_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_updated100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_12_13.csv')    \n",
    "    elif DATASET == 'Assistment2017':\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment2017_train{}.csv\".format(I))\n",
    "        valid_file = path.join(rootdir,DATASET,\"assistment2017_valid{}.csv\".format(I))\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment2017_test.csv\")\n",
    "        # Read embedding data\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assistment2017_skill_names_embeddings_300d.csv')\n",
    "        emb_file = path.join(rootdir, DATASET, 'assistment20017_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assistment2017_skill_names_embeddings_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_assistment2017.csv')    \n",
    "        \n",
    "    else :\n",
    "        print ('Dataset file not found')\n",
    "    \n",
    "    skill_names = pd.read_csv(sknames_file, sep=',', header=None).values\n",
    "    num_skills = skill_names.shape[0]     \n",
    "    \n",
    "    if USE_W2V:\n",
    "        embeddings = pd.read_csv(emb_file, sep=',', header=None)# \n",
    "        # Add a zero row at the beginning\n",
    "        embeddings = np.vstack((np.zeros([1,w2v_emb_size]), embeddings))   \n",
    "    else:\n",
    "        #embeddings = None\n",
    "        embeddings = np.zeros([num_skills,emb_size])\n",
    "        embeddings = np.vstack((np.zeros([1,emb_size]), embeddings))\n",
    "                   \n",
    "    start_user = 1\n",
    "    data_train, N_train = read_file_3lines(train_file, start_user)\n",
    "    start_user += N_train\n",
    "    data_valid, N_valid = read_file_3lines(valid_file, start_user)\n",
    "    start_user += N_valid\n",
    "    data_test, N_test = read_file_3lines(test_file, start_user)\n",
    "    return data_train, data_test, data_valid, embeddings, skill_names\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {
    "id": "QOnnR46SWXH1"
   },
   "outputs": [],
   "source": [
    "def read_data_test(DATASET = 'Assistment2009_corrected'):\n",
    "    if (DATASET == 'Assistment2009_corrected') :\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_train.csv\")\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment_2009_corrected_test.csv\")\n",
    "        # Read embedding data\n",
    "        #emb_file = path.join(rootdir, DATASET,'skill_name_embeddings_corrected.csv')\n",
    "        emb_file = path.join(rootdir, DATASET,'Assistment_2009_corrected_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_corrected_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_corrected.csv')\n",
    "        skill_names = pd.read_csv(sknames_file, sep=',', header=None).values\n",
    "        if mod == 'bigru_model':\n",
    "            spatd = 0.2\n",
    "            gausd = 0.2\n",
    "        elif mod == 'tdnn_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.6\n",
    "               \n",
    "    elif DATASET == 'assist2009_updated':\n",
    "        train_file = path.join(rootdir,DATASET,\"assist2009_updated_train.csv\")\n",
    "        test_file = path.join(rootdir,DATASET,\"assist2009_updated_test.csv\")\n",
    "        # Read embedding data        \n",
    "        #emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_updated300d.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assist2009_updated_skname_embeddings_FastText.csv')\n",
    "        emb_file = path.join(rootdir, DATASET, 'skill_name_embeddings_updated100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_updated.csv')\n",
    "        skill_names = pd.read_csv(sknames_file, sep=',', header=None).values\n",
    "        if mod == 'bigru_model':\n",
    "            spatd = 0.2\n",
    "            gausd = 0.2\n",
    "        elif mod == 'tdnn_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.6\n",
    "        \n",
    "    elif DATASET == 'fsaif1tof3': \n",
    "        train_file = path.join(rootdir,DATASET,\"fsaif1tof3_train.csv\")\n",
    "        test_file = path.join(rootdir,DATASET,\"fsaif1tof3_test.csv\")\n",
    "        # Read embedding data\n",
    "        emb_file = path.join(rootdir, DATASET,'fsaif1tof3_embeddings_300d.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET,'fsaif1tof3_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET,'fsaif1tof3_embeddings_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_name_question_id.csv')\n",
    "        skill_names = pd.read_csv(sknames_file, header=None).values\n",
    "        if mod == 'bigru_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.9\n",
    "        elif mod == 'tdnn_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.9\n",
    "        \n",
    "        \n",
    "    elif DATASET == 'Assistment2012_13':\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment2012_13_train.csv\")\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment2012_13_test.csv\")\n",
    "        # Read embedding data\n",
    "        #emb_file = path.join(rootdir, DATASET,'skill_name_embeddings_12_13.csv') #w2v 300d\n",
    "        #emb_file = path.join(rootdir, DATASET,'Assistment2012_13_skname_embeddings_FastText.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET,'skill_name_embeddings_12_13_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_12_13.csv')\n",
    "        skill_names = pd.read_csv(sknames_file, sep=',', header=None).values \n",
    "        if mod == 'bigru_model':\n",
    "            spatd = 0.2\n",
    "            gausd = 0.2\n",
    "        elif mod == 'tdnn_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.2\n",
    "    \n",
    "    elif DATASET == 'Assistment2017':\n",
    "        train_file = path.join(rootdir,DATASET,\"assistment2017_train.csv\")\n",
    "        test_file = path.join(rootdir,DATASET,\"assistment2017_test.csv\")\n",
    "        # Read embedding data\n",
    "        #emb_file = path.join(rootdir, DATASET, 'Assistment2017_skill_names_embeddings_300d.csv')\n",
    "        #emb_file = path.join(rootdir, DATASET, 'assistment20017_skname_embeddings_FastText.csv')\n",
    "        emb_file = path.join(rootdir, DATASET, 'Assistment2017_skill_names_embeddings_100d.csv')\n",
    "        # Read skill names\n",
    "        sknames_file = path.join(rootdir, DATASET,'skill_names_assistment2017.csv')\n",
    "        skill_names = pd.read_csv(sknames_file, sep=',', header=None).values\n",
    "        if mod == 'bigru_model':\n",
    "            spatd = 0.2\n",
    "            gausd = 0.2\n",
    "        elif mod == 'tdnn_model':\n",
    "            spatd = 0.5\n",
    "            gausd = 0.4\n",
    "    else :\n",
    "        print ('Dataset file not found')\n",
    "    \n",
    "        \n",
    "    num_skills = skill_names.shape[0]\n",
    "    \n",
    "    if USE_W2V:\n",
    "        embeddings = pd.read_csv(emb_file, sep=',', header=None)#\n",
    "        embeddings = np.vstack((np.zeros([1,w2v_emb_size]), embeddings))\n",
    "    else:\n",
    "        embeddings = np.zeros([num_skills,emb_size])\n",
    "        embeddings = np.vstack((np.zeros([1,emb_size]), embeddings))\n",
    "        \n",
    "    # Add a zero row at the beginning\n",
    "    #embeddings = np.vstack((np.zeros([1,w2v_emb_size]), embeddings))      \n",
    "         \n",
    "    start_user = 1\n",
    "    data_train, N_train = read_file_3lines(train_file, start_user)\n",
    "    start_user += N_train\n",
    "    data_test, N_test = read_file_3lines(test_file, start_user)\n",
    "    return data_train, data_test, embeddings, skill_names, spatd, gausd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "id": "UyuCVa60WoLu"
   },
   "outputs": [],
   "source": [
    "#%% Callback\n",
    "global keys\n",
    "global key_val_acc\n",
    "global key_val_auc\n",
    "global key_acc\n",
    "global key_auc\n",
    "\n",
    "def get_key(keystart, list):\n",
    "    for k in list:\n",
    "        if k[:len(keystart)] == keystart:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global keys\n",
    "        global key_val_acc\n",
    "        global key_val_auc\n",
    "        global key_acc\n",
    "        global key_auc\n",
    "        global filename\n",
    "        if keys==[]:\n",
    "            keys = list(logs.keys())\n",
    "            key_val_acc = get_key('val_acc', keys)\n",
    "            key_val_auc = get_key('val_auc', keys)\n",
    "            key_acc = get_key('acc', keys)\n",
    "            key_auc = get_key('auc', keys)\n",
    "            filename = 'tdnn_w2v-f{:d}'.format(fold)\\\n",
    "                +'-e{epoch:02d}'\\\n",
    "                +'-val_loss{val_loss:.4f}-val_accuracy{val_accuracy:.4f}'\\\n",
    "                +'-val_auc{'+key_val_auc+':.4f}'\\\n",
    "                +'.h5'\n",
    "            checkpoint.filepath = filename\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, beta):\n",
    "    if epoch < 10:\n",
    "        return beta\n",
    "    else:\n",
    "        return beta * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "callback1 = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {
    "id": "PespGhQkWw8L"
   },
   "outputs": [],
   "source": [
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-GRU model\n",
    "\n",
    "def model_bigru(num_hidden = [10], use_sigmoid=False):\n",
    "    num_hidden = num_hidden+[1]    # add the extra output layer\n",
    "    num_layers = len(num_hidden)\n",
    "    # Inputs\n",
    "    q_ids = Input(shape=[L], dtype=tf.int32)\n",
    "    hist = Input(shape=[L-1])\n",
    "    \n",
    "    if USE_W2V:\n",
    "        print(\"!!!!!!!!!!!! Using Pre-trained Skil name Embeddings!!!!\")\n",
    "        initial_emb = Constant(embeddings/(L*w2v_emb_size))\n",
    "        q = Embedding(embeddings.shape[0], w2v_emb_size,\n",
    "                    embeddings_initializer=initial_emb,mask_zero=True)(q_ids)  #, trainable=False\n",
    "        \n",
    "        initial_h_emb = RandomUniform(\n",
    "                        minval=-1/(w2v_emb_size*L), maxval=1/(w2v_emb_size*L))\n",
    "        hist_emb = Embedding(2, w2v_emb_size,\n",
    "                                   embeddings_initializer=initial_h_emb)(hist)\n",
    "    else:\n",
    "        print(\"!!!!!!!!!!!! Using Random Skil name Embeddings!!!!\")\n",
    "        initial_emb = RandomUniform(minval=-1/(emb_size*L),maxval=1/(emb_size*L))\n",
    "        q = Embedding(embeddings.shape[0], emb_size,\n",
    "                    embeddings_initializer=initial_emb)(q_ids)\n",
    "        \n",
    "        initial_h_emb = RandomUniform(\n",
    "                        minval=-1/(emb_size*L), maxval=1/(emb_size*L))\n",
    "        hist_emb = Embedding(2, emb_size,\n",
    "                                   embeddings_initializer=initial_h_emb)(hist)\n",
    "    \n",
    "    \n",
    "    print('q before conv:', q.shape)\n",
    "    print('hist before conv:', hist.shape)\n",
    "    \n",
    "    q = tf.keras.layers.SpatialDropout1D(spatd)(q) \n",
    "    #q_conv = Conv1D(filters=100, kernel_size=3, strides=1, activation=\"relu\")(q)\n",
    "    q_conv = Conv1D(filters=100, kernel_size=3, strides=1)(q)\n",
    "    #print('q after conv:', q_conv.shape)\n",
    "    q_conv = BatchNormalization()(q_conv)    \n",
    "    q_conv = Activation(\"relu\")(q_conv)    \n",
    "    #q_conv = Flatten()(q_conv)\n",
    "    \n",
    "    hist_emb = tf.keras.layers.SpatialDropout1D(spatd)(hist_emb)  \n",
    "    #hist_conv = Conv1D(filters=100, kernel_size=3, strides=1, activation=\"relu\")(hist_emb)\n",
    "    hist_conv = Conv1D(filters=100, kernel_size=3, strides=1)(hist_emb)\n",
    "    #print('hist after conv:', hist_conv.shape)\n",
    "    hist_conv = BatchNormalization()(hist_conv)    \n",
    "    hist_conv = Activation(\"relu\")(hist_conv)   \n",
    "    #hist_conv = Flatten()(hist_conv)\n",
    "    \n",
    "    #merged = Concatenate(axis=1)([q_conv, hist])\n",
    "    x = Concatenate(axis=1)([q_conv, hist_conv])\n",
    "    #print('merged ', merged.shape)      \n",
    "\n",
    "    x = Bidirectional(GRU(units=64, return_sequences=False))(x)\n",
    "    #print('lstm ', x_lstm.shape)\n",
    " \n",
    "    x = GaussianDropout(gausd)(x)\n",
    "\n",
    "    #x = Dropout(0.2)(x_lstm)\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        if layer == num_layers-1:\n",
    "            activation = \"sigmoid\"            \n",
    "        else:\n",
    "            activation = \"relu\"                  \n",
    "            x = Dense(num_hidden[layer], activation=activation)(x)     \n",
    "    \n",
    "    out = Dense(1, activation=activation)(x)\n",
    "   \n",
    "    model = Model(inputs=[q_ids, hist], outputs=out)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {
    "id": "SyUr3zxWWa-L"
   },
   "outputs": [],
   "source": [
    "#Time delay model\n",
    "#TDNN Model\n",
    "\n",
    "def model_tdnn(num_hidden = [10], use_sigmoid=False):\n",
    "    num_hidden = num_hidden+[1]    # add the extra output layer\n",
    "    num_layers = len(num_hidden)\n",
    "    # Inputs\n",
    "    q_ids = Input(shape=[L], dtype=tf.int32)\n",
    "    hist = Input(shape=[L-1])\n",
    "    \n",
    "    if USE_W2V:\n",
    "        print(\"!!!!!!!!!!!! Using Pre-trained Skil name Embeddings!!!!\")\n",
    "        initial_emb = Constant(embeddings/(L*w2v_emb_size))\n",
    "        q = Embedding(embeddings.shape[0], w2v_emb_size,\n",
    "                    embeddings_initializer=initial_emb,mask_zero=True)(q_ids)  #, trainable=False\n",
    "        \n",
    "        initial_h_emb = RandomUniform(\n",
    "                        minval=-1/(w2v_emb_size*L), maxval=1/(w2v_emb_size*L))\n",
    "        hist_emb = Embedding(2, w2v_emb_size,\n",
    "                                   embeddings_initializer=initial_h_emb)(hist)\n",
    "    else:\n",
    "        print(\"!!!!!!!!!!!! Using Random Skil name Embeddings!!!!\")\n",
    "        initial_emb = RandomUniform(minval=-1/(emb_size*L),maxval=1/(emb_size*L))\n",
    "        q = Embedding(embeddings.shape[0], emb_size,\n",
    "                    embeddings_initializer=initial_emb)(q_ids)\n",
    "        \n",
    "        initial_h_emb = RandomUniform(\n",
    "                        minval=-1/(emb_size*L), maxval=1/(emb_size*L))\n",
    "        hist_emb = Embedding(2, emb_size,\n",
    "                                   embeddings_initializer=initial_h_emb)(hist)\n",
    "    \n",
    "    \n",
    "    q = tf.keras.layers.SpatialDropout1D(spatd)(q)\n",
    "    q = Conv1D(50, 5)(q)\n",
    "    q = BatchNormalization()(q)    \n",
    "    q = Activation(\"relu\")(q)    \n",
    "    q = Flatten()(q)\n",
    "        \n",
    "    hist_emb = tf.keras.layers.SpatialDropout1D(spatd)(hist_emb)\n",
    "    hist_emb = Conv1D(50,5)(hist_emb)\n",
    "    hist_emb = BatchNormalization()(hist_emb)    \n",
    "    hist_emb = Activation(\"relu\")(hist_emb)   \n",
    "    hist_emb = Flatten()(hist_emb)\n",
    "    \n",
    "    x = Concatenate(axis=1)([q, hist_emb])\n",
    "    #x = Dense(20, activation=\"relu\")(x) \n",
    "    x = tf.keras.layers.GaussianDropout(gausd)(x)    \n",
    "   \n",
    "    for layer in range(num_layers):\n",
    "        if layer == num_layers-1:\n",
    "            activation = \"sigmoid\"\n",
    "            \n",
    "        else:\n",
    "            activation = \"relu\"                  \n",
    "            x = Dense(num_hidden[layer], activation=activation)(x)           \n",
    "   \n",
    "    out = Dense(1, activation=activation)(x)\n",
    "   \n",
    "    model = Model(inputs=[q_ids, hist], outputs=out)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {
    "id": "lHDmU-YaW0Eb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Train-Validation\\nfor fold in range(1,6):\\n    keys = []\\n    key_val_acc = None\\n    key_val_auc = None\\n    key_acc = None\\n    key_auc = None\\n    \\n    if USE_W2V:\\n        \\n        data_split_file = path.join(rootdir,DATASET,\"{}_split_{}_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,fold,L,w2v_emb_size))\\n    else:\\n        data_split_file = path.join(rootdir,DATASET,\"{}_split_{}_not_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,fold,L,emb_size))\\n        \\n    \\n    data_train, data_test,data_valid, embeddings, skill_names = read_data(DATASET=DATASET,I=fold)\\n    skill_ids = np.unique(np.hstack((\\n        data_train[:,1],\\n        data_valid[:,1],\\n        data_test[:,1]\\n    )))\\n    num_skills = len(skill_ids)\\n    train_user_ids = np.unique(data_train[:,0])\\n    valid_user_ids = np.unique(data_valid[:,0])\\n    test_user_ids = np.unique(data_test[:,0])\\n    N_train = len(train_user_ids)\\n    N_valid = len(valid_user_ids)\\n    N_test = len(test_user_ids)\\n    num_students = N_train + N_test + N_valid\\n    print(\\'Fold {}\\'.format (fold))\\n    print(\\'Number of skills: {}\\'.format(num_skills))\\n    print(\\'Number of train students: {}\\'.format(N_train))\\n    print(\\'Numberof validation students: {}\\'.format(N_valid))\\n    print(\\'Number of test students: {}\\'.format(N_test))\\n    print(\\'(total: {})\\'.format(num_students))\\n\\n# ### Generate `x_train`, `x_test`, `t_train`, `t_test`  \\n# Every student `stud_id` has a sequence of responses `correct[0], correct[1],..., correct[T-1]` for some skill `skill_id`. The length `T` of the sequence depends on the student and the skill.   \\n# Every row of `x_train` or `x_test` contains the `student_id`, the `skill_id` and the response `correct[t]` for some time `t`. In addition to that it also includes the history of length `L` of previous responses `correct[t-1],..., correct[t-L]`. These responses *must* correspond to the same student and the same skill as time `t`. If history is shorter than `L` then the missing entries are filled with `0`.\\n\\n    if not path.exists(data_split_file):\\n        \\n        #Generate Training, Validation and Testing data\\n        \\n        x_train, t_train = gen_inputs_targets(data_train,\\n                                train_user_ids, N_train, \\'Train set:\\')\\n        x_valid, t_valid = gen_inputs_targets(data_valid,\\n                                valid_user_ids, N_valid, \\'Validation set:\\')\\n        x_test, t_test = gen_inputs_targets(data_test,\\n                                test_user_ids, N_test, \\'Test set:\\')\\n        \\n        np.savez(data_split_file,\\n                    embeddings = embeddings,\\n                    x_train = x_train,\\n                    x_valid = x_valid,\\n                    x_test = x_test,\\n                    t_train = t_train,\\n                    t_valid = t_valid,\\n                    t_test = t_test,\\n                    train_user_ids = train_user_ids,\\n                    valid_user_ids = valid_user_ids,\\n                    test_user_ids = test_user_ids,\\n                    N_train = N_train,\\n                    N_valid = N_valid,\\n                    N_test = N_test,\\n                    num_skills = num_skills,\\n                    num_students = num_students)    \\n    else:\\n        data_split = np.load(data_split_file)\\n        embeddings = data_split[\\'embeddings\\']\\n        x_train = data_split[\\'x_train\\']\\n        x_test = data_split[\\'x_test\\']\\n        x_valid = data_split[\\'x_valid\\']\\n        t_train = data_split[\\'t_train\\']\\n        t_test = data_split[\\'t_test\\']\\n        t_valid = data_split[\\'t_valid\\']\\n        train_user_ids = data_split[\\'train_user_ids\\']\\n        valid_user_ids = data_split[\\'valid_user_ids\\']\\n        test_user_ids = data_split[\\'test_user_ids\\']\\n        N_train = data_split[\\'N_train\\']\\n        N_test = data_split[\\'N_test\\']\\n        N_valid = data_split[\\'N_valid\\']\\n        num_skills = data_split[\\'num_skills\\']\\n        num_students = data_split[\\'num_students\\']\\n \\n    #Train the model\\n    acc_valid_base = np.sum(t_valid==1)/t_valid.shape[0]\\n    print(\\'Baseline valid accuracy = {}\\'.format(acc_valid_base))   \\n    print(\"==================================================\")\\n    print(\\'L = {}, emb_size = {}, hidden={}\\'.format(L, emb_size, num_hidden))\\n    \\n    try:        \\n        del model \\n        K.clear_session()\\n    except:\\n        print(\"no model to delete\")\\n    \\n    if mod == \\'w2v_model\\':    \\n        model = model_tdnn_w2v(num_hidden=num_hidden, use_sigmoid=use_sigmoid)\\n    elif mod == \\'conv_model\\':    \\n        model = model_tdnn_conv(filters=num_filters, use_sigmoid=use_sigmoid)\\n    \\n    model.summary() \\n    \\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\\n                        filepath=None)\\n    my_callbacks = [\\n        MyCallback(),\\n        \\n        checkpoint\\n       \\n    ]\\n    \\n    model.compile(optimizer=Adamax(learning_rate=beta),\\n                loss= \\'binary_crossentropy\\', #MeanSquaredError(), #,\\n                metrics=[\\'accuracy\\', AUC()])\\n   \\n    history = model.fit([x_train[:,:L].astype(int), x_train[:,L:]], t_train,\\n                        validation_data=([x_valid[:,:L].astype(int), x_valid[:,L:]],t_valid),\\n                        epochs = max_epochs,\\n                        batch_size=batch_size,\\n                        verbose=1)#,\\n                        #callbacks=my_callbacks) #[ReduceLROnPlateau()]) #, , MyCallback()])\\n\\n    keys = history.history.keys()\\n    key_val_acc = get_key(\\'val_acc\\', keys)\\n    key_val_auc = get_key(\\'val_auc\\', keys)\\n    key_acc = get_key(\\'acc\\', keys)\\n    key_auc = get_key(\\'auc\\', keys)    \\n    \\n    plt.figure(figsize=(9,6))\\n    ep = np.arange(1,max_epochs+1)\\n    plt.plot(ep, history.history[key_val_auc], \\'r\\')\\n    plt.xticks(np.arange(0,max_epochs+1,5, dtype=np.int))\\n    plt.plot(ep, history.history[key_auc], \\'b\\')\\n    plt.plot(ep, history.history[key_val_acc], \\'r:\\')\\n    plt.plot(ep, history.history[key_acc], \\'b:\\')\\n    plt.legend([\\'val.auc\\', \\'auc\\', \\'val.acc\\', \\'acc\\'])\\n    plt.grid(b=True)\\n    if USE_W2V:\\n        title=\"DATASET={},split={},L={}, embsize={}, w2v={}, layers={}\".format(\\n                DATASET, fold, L, w2v_emb_size, True, num_hidden)\\n    else:\\n        title=\"DATASET={},split={}, L={}, embsize={}, w2v={}, layers={}\".format(\\n                DATASET, fold, L, emb_size, False, num_hidden)\\n    plt.title(title)\\n    plt.show()\\n    all_val_auc = np.array(history.history[key_val_auc])\\n    max_v_auc.append(max(all_val_auc))\\n\\nif USE_W2V:\\n    model_title=\"{}_L={}_embsize={}_w2v={}_use_sigmoid={}_layers={}.png\".format(\\n        DATASET, L, w2v_emb_size, True, use_sigmoid, num_hidden)\\nelse:\\n    model_title=\"{}_L={}_embsize={}_w2v={}_use_sigmoid={}_layers={}.png\".format(\\n        DATASET, L, emb_size, False, use_sigmoid, num_hidden)\\n\\nmodel_file = path.join(rootdir,DATASET,model_title)\\n\\ntf.keras.utils.plot_model(model, to_file=model_file, show_shapes=True)\\n\\n\\n#VALIDATION RESULT\\nav_val_auc = Average(max_v_auc)\\nprint(\\'Average validation auc of 5 folds cross-validation is {} \\'.format(av_val_auc))\\n'"
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Main\n",
    "'''\n",
    "# Train-Validation\n",
    "for fold in range(1,6):\n",
    "    keys = []\n",
    "    key_val_acc = None\n",
    "    key_val_auc = None\n",
    "    key_acc = None\n",
    "    key_auc = None\n",
    "    \n",
    "    if USE_W2V:\n",
    "        \n",
    "        data_split_file = path.join(rootdir,DATASET,\"{}_split_{}_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,fold,L,w2v_emb_size))\n",
    "    else:\n",
    "        data_split_file = path.join(rootdir,DATASET,\"{}_split_{}_not_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,fold,L,emb_size))\n",
    "        \n",
    "    \n",
    "    data_train, data_test,data_valid, embeddings, skill_names = read_data(DATASET=DATASET,I=fold)\n",
    "    skill_ids = np.unique(np.hstack((\n",
    "        data_train[:,1],\n",
    "        data_valid[:,1],\n",
    "        data_test[:,1]\n",
    "    )))\n",
    "    num_skills = len(skill_ids)\n",
    "    train_user_ids = np.unique(data_train[:,0])\n",
    "    valid_user_ids = np.unique(data_valid[:,0])\n",
    "    test_user_ids = np.unique(data_test[:,0])\n",
    "    N_train = len(train_user_ids)\n",
    "    N_valid = len(valid_user_ids)\n",
    "    N_test = len(test_user_ids)\n",
    "    num_students = N_train + N_test + N_valid\n",
    "    print('Fold {}'.format (fold))\n",
    "    print('Number of skills: {}'.format(num_skills))\n",
    "    print('Number of train students: {}'.format(N_train))\n",
    "    print('Numberof validation students: {}'.format(N_valid))\n",
    "    print('Number of test students: {}'.format(N_test))\n",
    "    print('(total: {})'.format(num_students))\n",
    "\n",
    "# ### Generate `x_train`, `x_test`, `t_train`, `t_test`  \n",
    "# Every student `stud_id` has a sequence of responses `correct[0], correct[1],..., correct[T-1]` for some skill `skill_id`. The length `T` of the sequence depends on the student and the skill.   \n",
    "# Every row of `x_train` or `x_test` contains the `student_id`, the `skill_id` and the response `correct[t]` for some time `t`. In addition to that it also includes the history of length `L` of previous responses `correct[t-1],..., correct[t-L]`. These responses *must* correspond to the same student and the same skill as time `t`. If history is shorter than `L` then the missing entries are filled with `0`.\n",
    "\n",
    "    if not path.exists(data_split_file):\n",
    "        \n",
    "        #Generate Training, Validation and Testing data\n",
    "        \n",
    "        x_train, t_train = gen_inputs_targets(data_train,\n",
    "                                train_user_ids, N_train, 'Train set:')\n",
    "        x_valid, t_valid = gen_inputs_targets(data_valid,\n",
    "                                valid_user_ids, N_valid, 'Validation set:')\n",
    "        x_test, t_test = gen_inputs_targets(data_test,\n",
    "                                test_user_ids, N_test, 'Test set:')\n",
    "        \n",
    "        np.savez(data_split_file,\n",
    "                    embeddings = embeddings,\n",
    "                    x_train = x_train,\n",
    "                    x_valid = x_valid,\n",
    "                    x_test = x_test,\n",
    "                    t_train = t_train,\n",
    "                    t_valid = t_valid,\n",
    "                    t_test = t_test,\n",
    "                    train_user_ids = train_user_ids,\n",
    "                    valid_user_ids = valid_user_ids,\n",
    "                    test_user_ids = test_user_ids,\n",
    "                    N_train = N_train,\n",
    "                    N_valid = N_valid,\n",
    "                    N_test = N_test,\n",
    "                    num_skills = num_skills,\n",
    "                    num_students = num_students)    \n",
    "    else:\n",
    "        data_split = np.load(data_split_file)\n",
    "        embeddings = data_split['embeddings']\n",
    "        x_train = data_split['x_train']\n",
    "        x_test = data_split['x_test']\n",
    "        x_valid = data_split['x_valid']\n",
    "        t_train = data_split['t_train']\n",
    "        t_test = data_split['t_test']\n",
    "        t_valid = data_split['t_valid']\n",
    "        train_user_ids = data_split['train_user_ids']\n",
    "        valid_user_ids = data_split['valid_user_ids']\n",
    "        test_user_ids = data_split['test_user_ids']\n",
    "        N_train = data_split['N_train']\n",
    "        N_test = data_split['N_test']\n",
    "        N_valid = data_split['N_valid']\n",
    "        num_skills = data_split['num_skills']\n",
    "        num_students = data_split['num_students']\n",
    " \n",
    "    #Train the model\n",
    "    acc_valid_base = np.sum(t_valid==1)/t_valid.shape[0]\n",
    "    print('Baseline valid accuracy = {}'.format(acc_valid_base))   \n",
    "    print(\"==================================================\")\n",
    "    print('L = {}, emb_size = {}, hidden={}'.format(L, emb_size, num_hidden))\n",
    "    \n",
    "    try:        \n",
    "        del model \n",
    "        K.clear_session()\n",
    "    except:\n",
    "        print(\"no model to delete\")\n",
    "    \n",
    "    if mod == 'w2v_model':    \n",
    "        model = model_tdnn_w2v(num_hidden=num_hidden, use_sigmoid=use_sigmoid)\n",
    "    elif mod == 'conv_model':    \n",
    "        model = model_tdnn_conv(filters=num_filters, use_sigmoid=use_sigmoid)\n",
    "    \n",
    "    model.summary() \n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                        filepath=None)\n",
    "    my_callbacks = [\n",
    "        MyCallback(),\n",
    "        \n",
    "        checkpoint\n",
    "       \n",
    "    ]\n",
    "    \n",
    "    model.compile(optimizer=Adamax(learning_rate=beta),\n",
    "                loss= 'binary_crossentropy', #MeanSquaredError(), #,\n",
    "                metrics=['accuracy', AUC()])\n",
    "   \n",
    "    history = model.fit([x_train[:,:L].astype(int), x_train[:,L:]], t_train,\n",
    "                        validation_data=([x_valid[:,:L].astype(int), x_valid[:,L:]],t_valid),\n",
    "                        epochs = max_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1)#,\n",
    "                        #callbacks=my_callbacks) #[ReduceLROnPlateau()]) #, , MyCallback()])\n",
    "\n",
    "    keys = history.history.keys()\n",
    "    key_val_acc = get_key('val_acc', keys)\n",
    "    key_val_auc = get_key('val_auc', keys)\n",
    "    key_acc = get_key('acc', keys)\n",
    "    key_auc = get_key('auc', keys)    \n",
    "    \n",
    "    plt.figure(figsize=(9,6))\n",
    "    ep = np.arange(1,max_epochs+1)\n",
    "    plt.plot(ep, history.history[key_val_auc], 'r')\n",
    "    plt.xticks(np.arange(0,max_epochs+1,5, dtype=np.int))\n",
    "    plt.plot(ep, history.history[key_auc], 'b')\n",
    "    plt.plot(ep, history.history[key_val_acc], 'r:')\n",
    "    plt.plot(ep, history.history[key_acc], 'b:')\n",
    "    plt.legend(['val.auc', 'auc', 'val.acc', 'acc'])\n",
    "    plt.grid(b=True)\n",
    "    if USE_W2V:\n",
    "        title=\"DATASET={},split={},L={}, embsize={}, w2v={}, layers={}\".format(\n",
    "                DATASET, fold, L, w2v_emb_size, True, num_hidden)\n",
    "    else:\n",
    "        title=\"DATASET={},split={}, L={}, embsize={}, w2v={}, layers={}\".format(\n",
    "                DATASET, fold, L, emb_size, False, num_hidden)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    all_val_auc = np.array(history.history[key_val_auc])\n",
    "    max_v_auc.append(max(all_val_auc))\n",
    "\n",
    "if USE_W2V:\n",
    "    model_title=\"{}_L={}_embsize={}_w2v={}_use_sigmoid={}_layers={}.png\".format(\n",
    "        DATASET, L, w2v_emb_size, True, use_sigmoid, num_hidden)\n",
    "else:\n",
    "    model_title=\"{}_L={}_embsize={}_w2v={}_use_sigmoid={}_layers={}.png\".format(\n",
    "        DATASET, L, emb_size, False, use_sigmoid, num_hidden)\n",
    "\n",
    "model_file = path.join(rootdir,DATASET,model_title)\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file=model_file, show_shapes=True)\n",
    "\n",
    "\n",
    "#VALIDATION RESULT\n",
    "av_val_auc = Average(max_v_auc)\n",
    "print('Average validation auc of 5 folds cross-validation is {} '.format(av_val_auc))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLM6faB-W-6b",
    "outputId": "ca861cfc-68cc-4223-cfa4-3da4d5620228",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===============EXPERIMENT NUMBER  1============\n",
      "~~~~~~~~~~~~~~~DATASET assist2009_updated ~~~~~~~~~~~\n",
      "Number of skills: 110\n",
      "Number of train students: 2921\n",
      "Number of test students: 1230\n",
      "(total: 4151)\n",
      "Baseline test accuracy = 0.6602920480292248\n",
      "==================================================\n",
      "L = 50, emb_size = 100, hidden=[50, 25], spatial dropout = 0.2, gaussian dropout = 0.2\n",
      "~~~~~~~~~~Train Bi-GRU MODEL~~~~~~~~\n",
      "!!!!!!!!!!!! Using Pre-trained Skil name Embeddings!!!!\n",
      "q before conv: (None, 50, 100)\n",
      "hist before conv: (None, 49)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 49)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 100)      11100       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 49, 100)      200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 50, 100)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 49, 100)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 48, 100)      30100       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 47, 100)      30100       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 48, 100)      400         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 100)      400         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 100)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 100)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 95, 100)      0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          63744       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_dropout (GaussianDropo (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           6450        gaussian_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25)           1275        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            26          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 143,795\n",
      "Trainable params: 143,395\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "6916/6916 [==============================] - 124s 18ms/step - loss: 0.4989 - accuracy: 0.7544 - auc: 0.7811 - val_loss: 0.4660 - val_accuracy: 0.7689 - val_auc: 0.8127\n",
      "Epoch 2/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4678 - accuracy: 0.7693 - auc: 0.8125 - val_loss: 0.4627 - val_accuracy: 0.7702 - val_auc: 0.8167\n",
      "Epoch 3/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4649 - accuracy: 0.7701 - auc: 0.8162 - val_loss: 0.4612 - val_accuracy: 0.7716 - val_auc: 0.8182\n",
      "Epoch 4/30\n",
      "6916/6916 [==============================] - 124s 18ms/step - loss: 0.4622 - accuracy: 0.7720 - auc: 0.8192 - val_loss: 0.4633 - val_accuracy: 0.7709 - val_auc: 0.8199\n",
      "Epoch 5/30\n",
      "6916/6916 [==============================] - 119s 17ms/step - loss: 0.4569 - accuracy: 0.7749 - auc: 0.8228 - val_loss: 0.4577 - val_accuracy: 0.7727 - val_auc: 0.8215\n",
      "Epoch 6/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4560 - accuracy: 0.7737 - auc: 0.8250 - val_loss: 0.4571 - val_accuracy: 0.7743 - val_auc: 0.8229\n",
      "Epoch 7/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4543 - accuracy: 0.7758 - auc: 0.8265 - val_loss: 0.4561 - val_accuracy: 0.7746 - val_auc: 0.8236\n",
      "Epoch 8/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4541 - accuracy: 0.7759 - auc: 0.8271 - val_loss: 0.4567 - val_accuracy: 0.7740 - val_auc: 0.8234\n",
      "Epoch 9/30\n",
      "6916/6916 [==============================] - 122s 18ms/step - loss: 0.4526 - accuracy: 0.7765 - auc: 0.8291 - val_loss: 0.4573 - val_accuracy: 0.7731 - val_auc: 0.8228\n",
      "Epoch 10/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4485 - accuracy: 0.7799 - auc: 0.8313 - val_loss: 0.4561 - val_accuracy: 0.7739 - val_auc: 0.8239\n",
      "Epoch 11/30\n",
      "6916/6916 [==============================] - 122s 18ms/step - loss: 0.4494 - accuracy: 0.7793 - auc: 0.8311 - val_loss: 0.4570 - val_accuracy: 0.7731 - val_auc: 0.8236\n",
      "Epoch 12/30\n",
      "6916/6916 [==============================] - 118s 17ms/step - loss: 0.4466 - accuracy: 0.7813 - auc: 0.8345 - val_loss: 0.4566 - val_accuracy: 0.7751 - val_auc: 0.8244\n",
      "Epoch 13/30\n",
      "6916/6916 [==============================] - 123s 18ms/step - loss: 0.4434 - accuracy: 0.7812 - auc: 0.8373 - val_loss: 0.4552 - val_accuracy: 0.7758 - val_auc: 0.8249\n",
      "Epoch 14/30\n",
      "6916/6916 [==============================] - 123s 18ms/step - loss: 0.4405 - accuracy: 0.7834 - auc: 0.8395 - val_loss: 0.4553 - val_accuracy: 0.7750 - val_auc: 0.8254\n",
      "Epoch 15/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4391 - accuracy: 0.7840 - auc: 0.8415 - val_loss: 0.4548 - val_accuracy: 0.7759 - val_auc: 0.8255\n",
      "Epoch 16/30\n",
      "6916/6916 [==============================] - 123s 18ms/step - loss: 0.4343 - accuracy: 0.7876 - auc: 0.8452 - val_loss: 0.4555 - val_accuracy: 0.7759 - val_auc: 0.8256\n",
      "Epoch 17/30\n",
      "6916/6916 [==============================] - 122s 18ms/step - loss: 0.4308 - accuracy: 0.7912 - auc: 0.8476 - val_loss: 0.4567 - val_accuracy: 0.7752 - val_auc: 0.8253\n",
      "Epoch 18/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4308 - accuracy: 0.7898 - auc: 0.8484 - val_loss: 0.4562 - val_accuracy: 0.7752 - val_auc: 0.8253\n",
      "Epoch 19/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4289 - accuracy: 0.7903 - auc: 0.8503 - val_loss: 0.4567 - val_accuracy: 0.7752 - val_auc: 0.8252\n",
      "Epoch 20/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4308 - accuracy: 0.7885 - auc: 0.8484 - val_loss: 0.4567 - val_accuracy: 0.7750 - val_auc: 0.8252\n",
      "Epoch 21/30\n",
      "6916/6916 [==============================] - 121s 18ms/step - loss: 0.4311 - accuracy: 0.7890 - auc: 0.8486 - val_loss: 0.4567 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 22/30\n",
      "6916/6916 [==============================] - 121s 18ms/step - loss: 0.4300 - accuracy: 0.7899 - auc: 0.8486 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 23/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4290 - accuracy: 0.7907 - auc: 0.8502 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 24/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4305 - accuracy: 0.7891 - auc: 0.8491 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 25/30\n",
      "6916/6916 [==============================] - 121s 17ms/step - loss: 0.4285 - accuracy: 0.7913 - auc: 0.8505 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 26/30\n",
      "6916/6916 [==============================] - 118s 17ms/step - loss: 0.4323 - accuracy: 0.7891 - auc: 0.8474 - val_loss: 0.4568 - val_accuracy: 0.7750 - val_auc: 0.8252\n",
      "Epoch 27/30\n",
      "6916/6916 [==============================] - 124s 18ms/step - loss: 0.4303 - accuracy: 0.7895 - auc: 0.8490 - val_loss: 0.4568 - val_accuracy: 0.7750 - val_auc: 0.8252\n",
      "Epoch 28/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4295 - accuracy: 0.7908 - auc: 0.8499 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "Epoch 29/30\n",
      "6916/6916 [==============================] - 124s 18ms/step - loss: 0.4284 - accuracy: 0.7911 - auc: 0.8500 - val_loss: 0.4568 - val_accuracy: 0.7752 - val_auc: 0.8252\n",
      "Epoch 30/30\n",
      "6916/6916 [==============================] - 120s 17ms/step - loss: 0.4303 - accuracy: 0.7910 - auc: 0.8485 - val_loss: 0.4568 - val_accuracy: 0.7751 - val_auc: 0.8252\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "!!!!!!!!!!!!!!!!! TEST RESULTS !!!!!!!!!!!!!!!!!!!!!\n",
      " =============== RESULTS OF EXPERIMENT NUMBER  1 ============\n",
      "Max test auc  is 0.8256485462188721 \n",
      "Average test auc  is 0.8235977133115132 \n"
     ]
    }
   ],
   "source": [
    "### Train Test\n",
    "#Train - test\n",
    "for count in range (1,2):\n",
    "    print(\" ===============EXPERIMENT NUMBER  {}============\".format(count))\n",
    "    print(\"~~~~~~~~~~~~~~~DATASET {} ~~~~~~~~~~~\".format(DATASET))\n",
    "    max_test_auc = []\n",
    "    \n",
    "    if USE_W2V:\n",
    "        data_file = path.join(rootdir,DATASET,\"{}_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,L,w2v_emb_size))\n",
    "    else:\n",
    "        data_file = path.join(rootdir,DATASET,\"{}_no_w2v_3lines_L{}_emb_size={}.npz\".format(DATASET,L,emb_size))\n",
    "        \n",
    "        \n",
    "    data_train, data_test, embeddings, skill_names, spatd, gausd = read_data_test(DATASET=DATASET)\n",
    "    skill_ids = np.unique(np.hstack((\n",
    "        data_train[:,1],\n",
    "        data_test[:,1]\n",
    "    )))\n",
    "    num_skills = len(skill_ids)\n",
    "    train_user_ids = np.unique(data_train[:,0])\n",
    "    test_user_ids = np.unique(data_test[:,0])\n",
    "    N_train = len(train_user_ids)\n",
    "    N_test = len(test_user_ids)\n",
    "    num_students = N_train + N_test\n",
    "    \n",
    "    print('Number of skills: {}'.format(num_skills))\n",
    "    print('Number of train students: {}'.format(N_train))\n",
    "    print('Number of test students: {}'.format(N_test))\n",
    "    print('(total: {})'.format(num_students))\n",
    "    \n",
    "    # ### Generate `x_train`, `x_test`, `t_train`, `t_test`  \n",
    "    # Every student `stud_id` has a sequence of responses `correct[0], correct[1],..., correct[T-1]` for some skill `skill_id`. The length `T` of the sequence depends on the student and the skill.   \n",
    "    # Every row of `x_train` or `x_test` contains the `student_id`, the `skill_id` and the response `correct[t]` for some time `t`. In addition to that it also includes the history of length `L` of previous responses `correct[t-1],..., correct[t-L]`. These responses *must* correspond to the same student and the same skill as time `t`. If history is shorter than `L` then the missing entries are filled with `0`.\n",
    "    \n",
    "    if not path.exists(data_file):\n",
    "        \n",
    "        #Generate Training, Validation and Testing data\n",
    "        \n",
    "        x_train, t_train = gen_inputs_targets(data_train,\n",
    "                                train_user_ids, N_train, 'Train set:')\n",
    "        x_test, t_test = gen_inputs_targets(data_test,\n",
    "                                test_user_ids, N_test, 'Test set:')\n",
    "        \n",
    "        np.savez(data_file,\n",
    "                    embeddings = embeddings,\n",
    "                    x_train = x_train,\n",
    "                    x_test = x_test,\n",
    "                    t_train = t_train,\n",
    "                    t_test = t_test,\n",
    "                    train_user_ids = train_user_ids,\n",
    "                    test_user_ids = test_user_ids,\n",
    "                    N_train = N_train,\n",
    "                    N_test = N_test,\n",
    "                    num_skills = num_skills,\n",
    "                    num_students = num_students)    \n",
    "    else:\n",
    "        data_split = np.load(data_file)\n",
    "        embeddings = data_split['embeddings']\n",
    "        x_train = data_split['x_train']\n",
    "        x_test = data_split['x_test']\n",
    "        t_train = data_split['t_train']\n",
    "        t_test = data_split['t_test']\n",
    "        train_user_ids = data_split['train_user_ids']\n",
    "        test_user_ids = data_split['test_user_ids']\n",
    "        N_train = data_split['N_train']\n",
    "        N_test = data_split['N_test']\n",
    "        num_skills = data_split['num_skills']\n",
    "        num_students = data_split['num_students']\n",
    "     \n",
    "    #Train the model\n",
    "    acc_test_base = np.sum(t_test==1)/t_test.shape[0]\n",
    "    print('Baseline test accuracy = {}'.format(acc_test_base))   \n",
    "    print(\"==================================================\")\n",
    "    if USE_W2V:\n",
    "        print('L = {}, emb_size = {}, hidden={}, spatial dropout = {}, gaussian dropout = {}'.format(\n",
    "                L, w2v_emb_size, num_hidden, spatd, gausd))\n",
    "    else:\n",
    "        print('L = {}, emb_size = {}, hidden={}, spatial dropout = {}, gaussian dropout = {}'.format(\n",
    "                L, emb_size, num_hidden, spatd, gausd))\n",
    "    \n",
    "    try:        \n",
    "        del model \n",
    "        K.clear_session()\n",
    "    except:\n",
    "        print(\"no model to delete\")\n",
    "    \n",
    "    if mod == 'tdnn_model':    \n",
    "        print(\"~~~~~~~Train TDNN MODEL~~~~~~~~~~\")\n",
    "        model = model_tdnn(num_hidden=num_hidden, use_sigmoid=use_sigmoid)    \n",
    "       \n",
    "        model.summary()   \n",
    "        model.compile(optimizer=Adamax(learning_rate=beta),\n",
    "                loss='binary_crossentropy',#MeanSquaredError(),# #\n",
    "                metrics=['accuracy', AUC()])\n",
    "    \n",
    "        history = model.fit([x_train[:,:L].astype(int), x_train[:,L:]], t_train,\n",
    "                           validation_data=([x_test[:,:L].astype(int), x_test[:,L:]],t_test),\n",
    "                           epochs = max_epochs,\n",
    "                           batch_size=batch_size,\n",
    "                           verbose=1,\n",
    "                           #callbacks=my_callbacks ) #[ReduceLROnPlateau()]) #, ), # MyCallback()])\n",
    "                       )\n",
    "    \n",
    "    \n",
    "    elif mod == 'bigru_model':    \n",
    "        print(\"~~~~~~~~~~Train Bi-GRU MODEL~~~~~~~~\")\n",
    "        model = model_bigru(num_hidden=num_hidden, use_sigmoid=use_sigmoid)   \n",
    "  \n",
    "        model.summary()\n",
    "        model.compile(optimizer=Adam(learning_rate=beta),\n",
    "            loss= 'binary_crossentropy',\n",
    "            metrics=['accuracy', AUC()])\n",
    "         \n",
    "        history = model.fit([x_train[:,:L].astype(int), x_train[:,L:]], t_train,\n",
    "                           validation_data=([x_test[:,:L].astype(int), x_test[:,L:]],t_test),\n",
    "                           epochs = max_epochs,\n",
    "                           batch_size=batch_size,\n",
    "                           verbose=1,\n",
    "                           callbacks=callback1\n",
    "                       )\n",
    "    \n",
    "    \n",
    "    #plot the model\n",
    "    if USE_W2V:\n",
    "        model_title=\"{}_L={}_embsize={}_w2v={}_layers={}.png\".format(\n",
    "                DATASET, L, w2v_emb_size, True, num_hidden)\n",
    "    else:\n",
    "        model_title=\"{}_L={}_embsize={}_w2v={}_layers={}.png\".format(\n",
    "                DATASET, L, emb_size, False, num_hidden)\n",
    "        \n",
    "    model_file = path.join(rootdir,DATASET,model_title)\n",
    "    tf.keras.utils.plot_model(model, to_file=model_file, show_shapes=True)    \n",
    "        \n",
    "    keys = history.history.keys()\n",
    "    key_val_acc = get_key('val_acc', keys)\n",
    "    key_val_auc = get_key('val_auc', keys)\n",
    "    key_acc = get_key('acc', keys)\n",
    "    key_auc = get_key('auc', keys)\n",
    "    \n",
    "        \n",
    "    print(\"!!!!!!!!!!!!!!!!! TEST RESULTS !!!!!!!!!!!!!!!!!!!!!\")\n",
    "    all_test_auc = np.array(history.history[key_val_auc])\n",
    "    max_test_auc.append(max(all_test_auc))\n",
    "    av_test_auc = Average(all_test_auc)\n",
    "    \n",
    "    print(\" =============== RESULTS OF EXPERIMENT NUMBER  {} ============\".format(count))\n",
    "    print('Max test auc  is {} '.format(max(all_test_auc)))\n",
    "    print('Average test auc  is {} '.format(av_test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~EVALUATION RESULTS ~~~~~~~\n",
      "3131/3131 [==============================] - 24s 8ms/step - loss: 0.4568 - accuracy: 0.7751 - auc: 0.8252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4567911922931671, 0.7750751376152039, 0.825153112411499]"
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"~~~~~EVALUATION RESULTS ~~~~~~~\")\n",
    "model.evaluate([x_test[:,:L].astype(int), x_test[:,L:].astype(int)],\n",
    "                            t_test,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "ep = np.arange(1,max_epochs+1)\n",
    "plt.plot(ep, history.history[key_val_auc], 'r')\n",
    "plt.xticks(np.arange(0,max_epochs+1,5, dtype=np.int))\n",
    "plt.plot(ep, history.history[key_auc], 'b')\n",
    "plt.plot(ep, history.history[key_val_acc], 'r:')\n",
    "plt.plot(ep, history.history[key_acc], 'b:')\n",
    "plt.legend(['test.auc', 'auc', 'test.acc', 'acc'])\n",
    "plt.grid(b=True)\n",
    "if USE_W2V:\n",
    "    title=\"model={},DATASET={},L={}, embsize={}, w2v={}, layers={}\".format(\n",
    "                mod, DATASET, L, w2v_emb_size, True, num_hidden)\n",
    "else:\n",
    "    title=\"model={},DATASET={}, L={}, embsize={}, w2v={}, layers={}\".format(\n",
    "            mod, DATASET, L, emb_size, False, num_hidden)\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPeRPhG+pQJ0G00gIzK/0PE",
   "collapsed_sections": [],
   "name": "tdnn-conv_edm_hist_emb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
